; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt %s -ompss-2 -S | FileCheck %s
; ModuleID = 'task_for_cond_and_register_check.ll'
source_filename = ""
target datalayout = ""
target triple = "x86_64-unknown-linux-gnu"

; void signed_loop_slt(int lb, int ub, int step) {
;     #pragma oss task for
;     for (int i = lb; i < ub; i += step) {}
; }
; void signed_loop_sle(int lb, int ub, int step) {
;     #pragma oss task for
;     for (int i = lb; i <= ub; i += step) {}
; }
; void signed_loop_sgt(int lb, int ub, int step) {
;     #pragma oss task for
;     for (int i = ub; i > lb; i -= step) {}
; }
; void signed_loop_sge(int lb, int ub, int step) {
;     #pragma oss task for
;     for (int i = ub; i >= lb; i -= step) {}
; }
; void unsigned_loop_slt(unsigned lb, unsigned ub, unsigned step) {
;     #pragma oss task for
;     for (unsigned i = lb; i < ub; i += step) {}
; }
; void unsigned_loop_sle(unsigned lb, unsigned ub, unsigned step) {
;     #pragma oss task for
;     for (unsigned i = lb; i <= ub; i += step) {}
; }
; void unsigned_loop_sgt(unsigned lb, unsigned ub, unsigned step) {
;     #pragma oss task for
;     for (unsigned i = ub; i > lb; i -= step) {}
; }
; void unsigned_loop_sge(unsigned lb, unsigned ub, unsigned step) {
;     #pragma oss task for
;     for (unsigned i = ub; i >= lb; i -= step) {}
; }
; void constants_loop() {
;     #pragma oss task for
;     for (int i = 0; i < 10; i += 1) {}
; }

; Function Attrs: noinline nounwind optnone
define void @signed_loop_slt(i32 %lb, i32 %ub, i32 %step) #0 !dbg !6 {
; CHECK-LABEL: @signed_loop_slt(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[LB_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[UB_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[STEP_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[I:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store i32 [[LB:%.*]], i32* [[LB_ADDR]], align 4
; CHECK-NEXT:    store i32 [[UB:%.*]], i32* [[UB_ADDR]], align 4
; CHECK-NEXT:    store i32 [[STEP:%.*]], i32* [[STEP_ADDR]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, i32* [[LB_ADDR]], align 4, [[DBG9:!dbg !.*]]
; CHECK-NEXT:    store i32 [[TMP0]], i32* [[I]], align 4, [[DBG9]]
; CHECK-NEXT:    [[TMP1:%.*]] = load i32, i32* [[LB_ADDR]], align 4, [[DBG9]]
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, i32* [[UB_ADDR]], align 4, [[DBG9]]
; CHECK-NEXT:    [[TMP3:%.*]] = load i32, i32* [[STEP_ADDR]], align 4, [[DBG9]]
; CHECK-NEXT:    [[TMP4:%.*]] = alloca %nanos6_task_args_signed_loop_slt0*, align 8, [[DBG9]]
; CHECK-NEXT:    [[TMP5:%.*]] = alloca i8*, align 8, [[DBG9]]
; CHECK-NEXT:    [[NUM_DEPS:%.*]] = alloca i64, align 8, [[DBG9]]
; CHECK-NEXT:    br label [[FINAL_COND:%.*]], [[DBG9]]
; CHECK:       codeRepl:
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast %nanos6_task_args_signed_loop_slt0** [[TMP4]] to i8**, [[DBG9]]
; CHECK-NEXT:    store i64 0, i64* [[NUM_DEPS]], align 4, [[DBG9]]
; CHECK-NEXT:    [[TMP7:%.*]] = load i64, i64* [[NUM_DEPS]], align 4, [[DBG9]]
; CHECK-NEXT:    [[TMP8:%.*]] = sub i32 [[TMP2]], [[TMP1]], [[DBG9]]
; CHECK-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP8]], 1, [[DBG9]]
; CHECK-NEXT:    [[TMP10:%.*]] = sdiv i32 [[TMP9]], [[TMP3]], [[DBG9]]
; CHECK-NEXT:    [[TMP11:%.*]] = add i32 [[TMP10]], 1, [[DBG9]]
; CHECK-NEXT:    [[TMP12:%.*]] = sext i32 [[TMP11]] to i64, [[DBG9]]
; CHECK-NEXT:    call void @nanos6_create_loop(%nanos6_task_info_t* @task_info_var_signed_loop_slt0, %nanos6_task_invocation_info_t* @task_invocation_info_signed_loop_slt0, i64 32, i8** [[TMP6]], i8** [[TMP5]], i64 8, i64 [[TMP7]], i64 0, i64 [[TMP12]], i64 0, i64 0), [[DBG9]]
; CHECK-NEXT:    [[TMP13:%.*]] = load %nanos6_task_args_signed_loop_slt0*, %nanos6_task_args_signed_loop_slt0** [[TMP4]], align 8, [[DBG9]]
; CHECK-NEXT:    [[TMP14:%.*]] = bitcast %nanos6_task_args_signed_loop_slt0* [[TMP13]] to i8*, [[DBG9]]
; CHECK-NEXT:    [[ARGS_END:%.*]] = getelementptr i8, i8* [[TMP14]], i64 32, [[DBG9]]
; CHECK-NEXT:    [[GEP_LB_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SLT0:%.*]], %nanos6_task_args_signed_loop_slt0* [[TMP13]], i32 0, i32 1, [[DBG9]]
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i32* [[GEP_LB_ADDR]] to i8*, [[DBG9]]
; CHECK-NEXT:    [[TMP16:%.*]] = bitcast i32* [[LB_ADDR]] to i8*, [[DBG9]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP15]], i8* align 4 [[TMP16]], i64 4, i1 false), [[DBG9]]
; CHECK-NEXT:    [[GEP_UB_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SLT0]], %nanos6_task_args_signed_loop_slt0* [[TMP13]], i32 0, i32 2, [[DBG9]]
; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i32* [[GEP_UB_ADDR]] to i8*, [[DBG9]]
; CHECK-NEXT:    [[TMP18:%.*]] = bitcast i32* [[UB_ADDR]] to i8*, [[DBG9]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP17]], i8* align 4 [[TMP18]], i64 4, i1 false), [[DBG9]]
; CHECK-NEXT:    [[GEP_STEP_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SLT0]], %nanos6_task_args_signed_loop_slt0* [[TMP13]], i32 0, i32 3, [[DBG9]]
; CHECK-NEXT:    [[TMP19:%.*]] = bitcast i32* [[GEP_STEP_ADDR]] to i8*, [[DBG9]]
; CHECK-NEXT:    [[TMP20:%.*]] = bitcast i32* [[STEP_ADDR]] to i8*, [[DBG9]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP19]], i8* align 4 [[TMP20]], i64 4, i1 false), [[DBG9]]
; CHECK-NEXT:    [[CAPT_GEP_:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SLT0]], %nanos6_task_args_signed_loop_slt0* [[TMP13]], i32 0, i32 4, [[DBG9]]
; CHECK-NEXT:    store i32 [[TMP1]], i32* [[CAPT_GEP_]], align 4, [[DBG9]]
; CHECK-NEXT:    [[CAPT_GEP_6:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SLT0]], %nanos6_task_args_signed_loop_slt0* [[TMP13]], i32 0, i32 5, [[DBG9]]
; CHECK-NEXT:    store i32 [[TMP2]], i32* [[CAPT_GEP_6]], align 4, [[DBG9]]
; CHECK-NEXT:    [[CAPT_GEP_7:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SLT0]], %nanos6_task_args_signed_loop_slt0* [[TMP13]], i32 0, i32 6, [[DBG9]]
; CHECK-NEXT:    store i32 [[TMP3]], i32* [[CAPT_GEP_7]], align 4, [[DBG9]]
; CHECK-NEXT:    [[TMP21:%.*]] = load i8*, i8** [[TMP5]], align 8, [[DBG9]]
; CHECK-NEXT:    call void @nanos6_submit_task(i8* [[TMP21]]), [[DBG9]]
; CHECK-NEXT:    br label [[FINAL_END:%.*]], [[DBG9]]
; CHECK:       final.end:
; CHECK-NEXT:    ret void, [[DBG10:!dbg !.*]]
; CHECK:       final.then:
; CHECK-NEXT:    store i32 [[TMP1]], i32* [[I]], align 4, [[DBG9]]
; CHECK-NEXT:    br label [[FOR_COND:%.*]], [[DBG9]]
; CHECK:       for.cond:
; CHECK-NEXT:    [[TMP22:%.*]] = load i32, i32* [[I]], align 4, [[DBG9]]
; CHECK-NEXT:    [[TMP23:%.*]] = icmp slt i32 [[TMP22]], [[TMP2]], [[DBG9]]
; CHECK-NEXT:    br i1 [[TMP23]], label [[FOR_BODY:%.*]], label [[FINAL_END]], [[DBG9]]
; CHECK:       for.body:
; CHECK-NEXT:    br label [[FOR_INCR:%.*]], [[DBG10]]
; CHECK:       for.incr:
; CHECK-NEXT:    [[TMP24:%.*]] = load i32, i32* [[I]], align 4, [[DBG9]]
; CHECK-NEXT:    [[TMP25:%.*]] = add i32 [[TMP24]], [[TMP3]], [[DBG9]]
; CHECK-NEXT:    store i32 [[TMP25]], i32* [[I]], align 4, [[DBG9]]
; CHECK-NEXT:    br label [[FOR_COND]], [[DBG9]]
; CHECK:       final.cond:
; CHECK-NEXT:    [[TMP26:%.*]] = call i32 @nanos6_in_final(), [[DBG9]]
; CHECK-NEXT:    [[TMP27:%.*]] = icmp ne i32 [[TMP26]], 0, [[DBG9]]
; CHECK-NEXT:    br i1 [[TMP27]], label [[FINAL_THEN:%.*]], label [[CODEREPL:%.*]], [[DBG9]]
;
entry:
  %lb.addr = alloca i32, align 4
  %ub.addr = alloca i32, align 4
  %step.addr = alloca i32, align 4
  %i = alloca i32, align 4
  store i32 %lb, i32* %lb.addr, align 4
  store i32 %ub, i32* %ub.addr, align 4
  store i32 %step, i32* %step.addr, align 4
  %0 = load i32, i32* %lb.addr, align 4, !dbg !9
  store i32 %0, i32* %i, align 4, !dbg !9
  %1 = load i32, i32* %lb.addr, align 4, !dbg !9
  %2 = load i32, i32* %ub.addr, align 4, !dbg !9
  %3 = load i32, i32* %step.addr, align 4, !dbg !9
  %4 = call token @llvm.directive.region.entry() [ "DIR.OSS"([9 x i8] c"TASK.FOR\00"), "QUAL.OSS.PRIVATE"(i32* %i), "QUAL.OSS.FIRSTPRIVATE"(i32* %lb.addr), "QUAL.OSS.FIRSTPRIVATE"(i32* %ub.addr), "QUAL.OSS.FIRSTPRIVATE"(i32* %step.addr), "QUAL.OSS.LOOP.IND.VAR"(i32* %i), "QUAL.OSS.LOOP.LOWER.BOUND"(i32 %1), "QUAL.OSS.LOOP.UPPER.BOUND"(i32 %2), "QUAL.OSS.LOOP.STEP"(i32 %3), "QUAL.OSS.LOOP.TYPE"(i64 0, i64 1, i64 1, i64 1, i64 1), "QUAL.OSS.CAPTURED"(i32 %1, i32 %2, i32 %3) ], !dbg !9
  call void @llvm.directive.region.exit(token %4), !dbg !9
  ret void, !dbg !10
}

; Function Attrs: nounwind
declare token @llvm.directive.region.entry() #1

; Function Attrs: nounwind
declare void @llvm.directive.region.exit(token) #1

; Function Attrs: noinline nounwind optnone
define void @signed_loop_sle(i32 %lb, i32 %ub, i32 %step) #0 !dbg !11 {
; CHECK-LABEL: @signed_loop_sle(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[LB_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[UB_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[STEP_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[I:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store i32 [[LB:%.*]], i32* [[LB_ADDR]], align 4
; CHECK-NEXT:    store i32 [[UB:%.*]], i32* [[UB_ADDR]], align 4
; CHECK-NEXT:    store i32 [[STEP:%.*]], i32* [[STEP_ADDR]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, i32* [[LB_ADDR]], align 4, [[DBG12:!dbg !.*]]
; CHECK-NEXT:    store i32 [[TMP0]], i32* [[I]], align 4, [[DBG12]]
; CHECK-NEXT:    [[TMP1:%.*]] = load i32, i32* [[LB_ADDR]], align 4, [[DBG12]]
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, i32* [[UB_ADDR]], align 4, [[DBG12]]
; CHECK-NEXT:    [[TMP3:%.*]] = load i32, i32* [[STEP_ADDR]], align 4, [[DBG12]]
; CHECK-NEXT:    [[TMP4:%.*]] = alloca %nanos6_task_args_signed_loop_sle0*, align 8, [[DBG12]]
; CHECK-NEXT:    [[TMP5:%.*]] = alloca i8*, align 8, [[DBG12]]
; CHECK-NEXT:    [[NUM_DEPS:%.*]] = alloca i64, align 8, [[DBG12]]
; CHECK-NEXT:    br label [[FINAL_COND:%.*]], [[DBG12]]
; CHECK:       codeRepl:
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast %nanos6_task_args_signed_loop_sle0** [[TMP4]] to i8**, [[DBG12]]
; CHECK-NEXT:    store i64 0, i64* [[NUM_DEPS]], align 4, [[DBG12]]
; CHECK-NEXT:    [[TMP7:%.*]] = load i64, i64* [[NUM_DEPS]], align 4, [[DBG12]]
; CHECK-NEXT:    [[TMP8:%.*]] = sub i32 [[TMP2]], [[TMP1]], [[DBG12]]
; CHECK-NEXT:    [[TMP9:%.*]] = sdiv i32 [[TMP8]], [[TMP3]], [[DBG12]]
; CHECK-NEXT:    [[TMP10:%.*]] = add i32 [[TMP9]], 1, [[DBG12]]
; CHECK-NEXT:    [[TMP11:%.*]] = sext i32 [[TMP10]] to i64, [[DBG12]]
; CHECK-NEXT:    call void @nanos6_create_loop(%nanos6_task_info_t* @task_info_var_signed_loop_sle0, %nanos6_task_invocation_info_t* @task_invocation_info_signed_loop_sle0, i64 32, i8** [[TMP6]], i8** [[TMP5]], i64 8, i64 [[TMP7]], i64 0, i64 [[TMP11]], i64 0, i64 0), [[DBG12]]
; CHECK-NEXT:    [[TMP12:%.*]] = load %nanos6_task_args_signed_loop_sle0*, %nanos6_task_args_signed_loop_sle0** [[TMP4]], align 8, [[DBG12]]
; CHECK-NEXT:    [[TMP13:%.*]] = bitcast %nanos6_task_args_signed_loop_sle0* [[TMP12]] to i8*, [[DBG12]]
; CHECK-NEXT:    [[ARGS_END:%.*]] = getelementptr i8, i8* [[TMP13]], i64 32, [[DBG12]]
; CHECK-NEXT:    [[GEP_LB_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SLE0:%.*]], %nanos6_task_args_signed_loop_sle0* [[TMP12]], i32 0, i32 1, [[DBG12]]
; CHECK-NEXT:    [[TMP14:%.*]] = bitcast i32* [[GEP_LB_ADDR]] to i8*, [[DBG12]]
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i32* [[LB_ADDR]] to i8*, [[DBG12]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP14]], i8* align 4 [[TMP15]], i64 4, i1 false), [[DBG12]]
; CHECK-NEXT:    [[GEP_UB_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SLE0]], %nanos6_task_args_signed_loop_sle0* [[TMP12]], i32 0, i32 2, [[DBG12]]
; CHECK-NEXT:    [[TMP16:%.*]] = bitcast i32* [[GEP_UB_ADDR]] to i8*, [[DBG12]]
; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i32* [[UB_ADDR]] to i8*, [[DBG12]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP16]], i8* align 4 [[TMP17]], i64 4, i1 false), [[DBG12]]
; CHECK-NEXT:    [[GEP_STEP_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SLE0]], %nanos6_task_args_signed_loop_sle0* [[TMP12]], i32 0, i32 3, [[DBG12]]
; CHECK-NEXT:    [[TMP18:%.*]] = bitcast i32* [[GEP_STEP_ADDR]] to i8*, [[DBG12]]
; CHECK-NEXT:    [[TMP19:%.*]] = bitcast i32* [[STEP_ADDR]] to i8*, [[DBG12]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP18]], i8* align 4 [[TMP19]], i64 4, i1 false), [[DBG12]]
; CHECK-NEXT:    [[CAPT_GEP_:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SLE0]], %nanos6_task_args_signed_loop_sle0* [[TMP12]], i32 0, i32 4, [[DBG12]]
; CHECK-NEXT:    store i32 [[TMP1]], i32* [[CAPT_GEP_]], align 4, [[DBG12]]
; CHECK-NEXT:    [[CAPT_GEP_6:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SLE0]], %nanos6_task_args_signed_loop_sle0* [[TMP12]], i32 0, i32 5, [[DBG12]]
; CHECK-NEXT:    store i32 [[TMP2]], i32* [[CAPT_GEP_6]], align 4, [[DBG12]]
; CHECK-NEXT:    [[CAPT_GEP_7:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SLE0]], %nanos6_task_args_signed_loop_sle0* [[TMP12]], i32 0, i32 6, [[DBG12]]
; CHECK-NEXT:    store i32 [[TMP3]], i32* [[CAPT_GEP_7]], align 4, [[DBG12]]
; CHECK-NEXT:    [[TMP20:%.*]] = load i8*, i8** [[TMP5]], align 8, [[DBG12]]
; CHECK-NEXT:    call void @nanos6_submit_task(i8* [[TMP20]]), [[DBG12]]
; CHECK-NEXT:    br label [[FINAL_END:%.*]], [[DBG12]]
; CHECK:       final.end:
; CHECK-NEXT:    ret void, [[DBG13:!dbg !.*]]
; CHECK:       final.then:
; CHECK-NEXT:    store i32 [[TMP1]], i32* [[I]], align 4, [[DBG12]]
; CHECK-NEXT:    br label [[FOR_COND:%.*]], [[DBG12]]
; CHECK:       for.cond:
; CHECK-NEXT:    [[TMP21:%.*]] = load i32, i32* [[I]], align 4, [[DBG12]]
; CHECK-NEXT:    [[TMP22:%.*]] = icmp sle i32 [[TMP21]], [[TMP2]], [[DBG12]]
; CHECK-NEXT:    br i1 [[TMP22]], label [[FOR_BODY:%.*]], label [[FINAL_END]], [[DBG12]]
; CHECK:       for.body:
; CHECK-NEXT:    br label [[FOR_INCR:%.*]], [[DBG13]]
; CHECK:       for.incr:
; CHECK-NEXT:    [[TMP23:%.*]] = load i32, i32* [[I]], align 4, [[DBG12]]
; CHECK-NEXT:    [[TMP24:%.*]] = add i32 [[TMP23]], [[TMP3]], [[DBG12]]
; CHECK-NEXT:    store i32 [[TMP24]], i32* [[I]], align 4, [[DBG12]]
; CHECK-NEXT:    br label [[FOR_COND]], [[DBG12]]
; CHECK:       final.cond:
; CHECK-NEXT:    [[TMP25:%.*]] = call i32 @nanos6_in_final(), [[DBG12]]
; CHECK-NEXT:    [[TMP26:%.*]] = icmp ne i32 [[TMP25]], 0, [[DBG12]]
; CHECK-NEXT:    br i1 [[TMP26]], label [[FINAL_THEN:%.*]], label [[CODEREPL:%.*]], [[DBG12]]
;
entry:
  %lb.addr = alloca i32, align 4
  %ub.addr = alloca i32, align 4
  %step.addr = alloca i32, align 4
  %i = alloca i32, align 4
  store i32 %lb, i32* %lb.addr, align 4
  store i32 %ub, i32* %ub.addr, align 4
  store i32 %step, i32* %step.addr, align 4
  %0 = load i32, i32* %lb.addr, align 4, !dbg !12
  store i32 %0, i32* %i, align 4, !dbg !12
  %1 = load i32, i32* %lb.addr, align 4, !dbg !12
  %2 = load i32, i32* %ub.addr, align 4, !dbg !12
  %3 = load i32, i32* %step.addr, align 4, !dbg !12
  %4 = call token @llvm.directive.region.entry() [ "DIR.OSS"([9 x i8] c"TASK.FOR\00"), "QUAL.OSS.PRIVATE"(i32* %i), "QUAL.OSS.FIRSTPRIVATE"(i32* %lb.addr), "QUAL.OSS.FIRSTPRIVATE"(i32* %ub.addr), "QUAL.OSS.FIRSTPRIVATE"(i32* %step.addr), "QUAL.OSS.LOOP.IND.VAR"(i32* %i), "QUAL.OSS.LOOP.LOWER.BOUND"(i32 %1), "QUAL.OSS.LOOP.UPPER.BOUND"(i32 %2), "QUAL.OSS.LOOP.STEP"(i32 %3), "QUAL.OSS.LOOP.TYPE"(i64 1, i64 1, i64 1, i64 1, i64 1), "QUAL.OSS.CAPTURED"(i32 %1, i32 %2, i32 %3) ], !dbg !12
  call void @llvm.directive.region.exit(token %4), !dbg !12
  ret void, !dbg !13
}

; Function Attrs: noinline nounwind optnone
define void @signed_loop_sgt(i32 %lb, i32 %ub, i32 %step) #0 !dbg !14 {
; CHECK-LABEL: @signed_loop_sgt(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[LB_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[UB_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[STEP_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[I:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store i32 [[LB:%.*]], i32* [[LB_ADDR]], align 4
; CHECK-NEXT:    store i32 [[UB:%.*]], i32* [[UB_ADDR]], align 4
; CHECK-NEXT:    store i32 [[STEP:%.*]], i32* [[STEP_ADDR]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, i32* [[UB_ADDR]], align 4, [[DBG15:!dbg !.*]]
; CHECK-NEXT:    store i32 [[TMP0]], i32* [[I]], align 4, [[DBG15]]
; CHECK-NEXT:    [[TMP1:%.*]] = load i32, i32* [[UB_ADDR]], align 4, [[DBG15]]
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, i32* [[UB_ADDR]], align 4, [[DBG15]]
; CHECK-NEXT:    [[TMP3:%.*]] = load i32, i32* [[STEP_ADDR]], align 4, [[DBG15]]
; CHECK-NEXT:    [[TMP4:%.*]] = alloca %nanos6_task_args_signed_loop_sgt0*, align 8, [[DBG15]]
; CHECK-NEXT:    [[TMP5:%.*]] = alloca i8*, align 8, [[DBG15]]
; CHECK-NEXT:    [[NUM_DEPS:%.*]] = alloca i64, align 8, [[DBG15]]
; CHECK-NEXT:    br label [[FINAL_COND:%.*]], [[DBG15]]
; CHECK:       codeRepl:
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast %nanos6_task_args_signed_loop_sgt0** [[TMP4]] to i8**, [[DBG15]]
; CHECK-NEXT:    store i64 0, i64* [[NUM_DEPS]], align 4, [[DBG15]]
; CHECK-NEXT:    [[TMP7:%.*]] = load i64, i64* [[NUM_DEPS]], align 4, [[DBG15]]
; CHECK-NEXT:    [[TMP8:%.*]] = sub i32 [[TMP2]], [[TMP1]], [[DBG15]]
; CHECK-NEXT:    [[TMP9:%.*]] = add i32 [[TMP8]], 1, [[DBG15]]
; CHECK-NEXT:    [[TMP10:%.*]] = sdiv i32 [[TMP9]], [[TMP3]], [[DBG15]]
; CHECK-NEXT:    [[TMP11:%.*]] = add i32 [[TMP10]], 1, [[DBG15]]
; CHECK-NEXT:    [[TMP12:%.*]] = sext i32 [[TMP11]] to i64, [[DBG15]]
; CHECK-NEXT:    call void @nanos6_create_loop(%nanos6_task_info_t* @task_info_var_signed_loop_sgt0, %nanos6_task_invocation_info_t* @task_invocation_info_signed_loop_sgt0, i64 32, i8** [[TMP6]], i8** [[TMP5]], i64 8, i64 [[TMP7]], i64 0, i64 [[TMP12]], i64 0, i64 0), [[DBG15]]
; CHECK-NEXT:    [[TMP13:%.*]] = load %nanos6_task_args_signed_loop_sgt0*, %nanos6_task_args_signed_loop_sgt0** [[TMP4]], align 8, [[DBG15]]
; CHECK-NEXT:    [[TMP14:%.*]] = bitcast %nanos6_task_args_signed_loop_sgt0* [[TMP13]] to i8*, [[DBG15]]
; CHECK-NEXT:    [[ARGS_END:%.*]] = getelementptr i8, i8* [[TMP14]], i64 32, [[DBG15]]
; CHECK-NEXT:    [[GEP_UB_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SGT0:%.*]], %nanos6_task_args_signed_loop_sgt0* [[TMP13]], i32 0, i32 1, [[DBG15]]
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i32* [[GEP_UB_ADDR]] to i8*, [[DBG15]]
; CHECK-NEXT:    [[TMP16:%.*]] = bitcast i32* [[UB_ADDR]] to i8*, [[DBG15]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP15]], i8* align 4 [[TMP16]], i64 4, i1 false), [[DBG15]]
; CHECK-NEXT:    [[GEP_STEP_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SGT0]], %nanos6_task_args_signed_loop_sgt0* [[TMP13]], i32 0, i32 2, [[DBG15]]
; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i32* [[GEP_STEP_ADDR]] to i8*, [[DBG15]]
; CHECK-NEXT:    [[TMP18:%.*]] = bitcast i32* [[STEP_ADDR]] to i8*, [[DBG15]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP17]], i8* align 4 [[TMP18]], i64 4, i1 false), [[DBG15]]
; CHECK-NEXT:    [[CAPT_GEP_:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SGT0]], %nanos6_task_args_signed_loop_sgt0* [[TMP13]], i32 0, i32 3, [[DBG15]]
; CHECK-NEXT:    store i32 [[TMP1]], i32* [[CAPT_GEP_]], align 4, [[DBG15]]
; CHECK-NEXT:    [[CAPT_GEP_6:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SGT0]], %nanos6_task_args_signed_loop_sgt0* [[TMP13]], i32 0, i32 4, [[DBG15]]
; CHECK-NEXT:    store i32 [[TMP2]], i32* [[CAPT_GEP_6]], align 4, [[DBG15]]
; CHECK-NEXT:    [[CAPT_GEP_7:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SGT0]], %nanos6_task_args_signed_loop_sgt0* [[TMP13]], i32 0, i32 5, [[DBG15]]
; CHECK-NEXT:    store i32 [[TMP3]], i32* [[CAPT_GEP_7]], align 4, [[DBG15]]
; CHECK-NEXT:    [[TMP19:%.*]] = load i8*, i8** [[TMP5]], align 8, [[DBG15]]
; CHECK-NEXT:    call void @nanos6_submit_task(i8* [[TMP19]]), [[DBG15]]
; CHECK-NEXT:    br label [[FINAL_END:%.*]], [[DBG15]]
; CHECK:       final.end:
; CHECK-NEXT:    ret void, [[DBG16:!dbg !.*]]
; CHECK:       final.then:
; CHECK-NEXT:    store i32 [[TMP1]], i32* [[I]], align 4, [[DBG15]]
; CHECK-NEXT:    br label [[FOR_COND:%.*]], [[DBG15]]
; CHECK:       for.cond:
; CHECK-NEXT:    [[TMP20:%.*]] = load i32, i32* [[I]], align 4, [[DBG15]]
; CHECK-NEXT:    [[TMP21:%.*]] = icmp sgt i32 [[TMP20]], [[TMP2]], [[DBG15]]
; CHECK-NEXT:    br i1 [[TMP21]], label [[FOR_BODY:%.*]], label [[FINAL_END]], [[DBG15]]
; CHECK:       for.body:
; CHECK-NEXT:    br label [[FOR_INCR:%.*]], [[DBG16]]
; CHECK:       for.incr:
; CHECK-NEXT:    [[TMP22:%.*]] = load i32, i32* [[I]], align 4, [[DBG15]]
; CHECK-NEXT:    [[TMP23:%.*]] = add i32 [[TMP22]], [[TMP3]], [[DBG15]]
; CHECK-NEXT:    store i32 [[TMP23]], i32* [[I]], align 4, [[DBG15]]
; CHECK-NEXT:    br label [[FOR_COND]], [[DBG15]]
; CHECK:       final.cond:
; CHECK-NEXT:    [[TMP24:%.*]] = call i32 @nanos6_in_final(), [[DBG15]]
; CHECK-NEXT:    [[TMP25:%.*]] = icmp ne i32 [[TMP24]], 0, [[DBG15]]
; CHECK-NEXT:    br i1 [[TMP25]], label [[FINAL_THEN:%.*]], label [[CODEREPL:%.*]], [[DBG15]]
;
entry:
  %lb.addr = alloca i32, align 4
  %ub.addr = alloca i32, align 4
  %step.addr = alloca i32, align 4
  %i = alloca i32, align 4
  store i32 %lb, i32* %lb.addr, align 4
  store i32 %ub, i32* %ub.addr, align 4
  store i32 %step, i32* %step.addr, align 4
  %0 = load i32, i32* %ub.addr, align 4, !dbg !15
  store i32 %0, i32* %i, align 4, !dbg !15
  %1 = load i32, i32* %ub.addr, align 4, !dbg !15
  %2 = load i32, i32* %ub.addr, align 4, !dbg !15
  %3 = load i32, i32* %step.addr, align 4, !dbg !15
  %4 = call token @llvm.directive.region.entry() [ "DIR.OSS"([9 x i8] c"TASK.FOR\00"), "QUAL.OSS.PRIVATE"(i32* %i), "QUAL.OSS.FIRSTPRIVATE"(i32* %ub.addr), "QUAL.OSS.FIRSTPRIVATE"(i32* %step.addr), "QUAL.OSS.LOOP.IND.VAR"(i32* %i), "QUAL.OSS.LOOP.LOWER.BOUND"(i32 %1), "QUAL.OSS.LOOP.UPPER.BOUND"(i32 %2), "QUAL.OSS.LOOP.STEP"(i32 %3), "QUAL.OSS.LOOP.TYPE"(i64 2, i64 1, i64 1, i64 1, i64 1), "QUAL.OSS.CAPTURED"(i32 %1, i32 %2, i32 %3) ], !dbg !15
  call void @llvm.directive.region.exit(token %4), !dbg !15
  ret void, !dbg !16
}

; Function Attrs: noinline nounwind optnone
define void @signed_loop_sge(i32 %lb, i32 %ub, i32 %step) #0 !dbg !17 {
; CHECK-LABEL: @signed_loop_sge(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[LB_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[UB_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[STEP_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[I:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store i32 [[LB:%.*]], i32* [[LB_ADDR]], align 4
; CHECK-NEXT:    store i32 [[UB:%.*]], i32* [[UB_ADDR]], align 4
; CHECK-NEXT:    store i32 [[STEP:%.*]], i32* [[STEP_ADDR]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, i32* [[UB_ADDR]], align 4, [[DBG18:!dbg !.*]]
; CHECK-NEXT:    store i32 [[TMP0]], i32* [[I]], align 4, [[DBG18]]
; CHECK-NEXT:    [[TMP1:%.*]] = load i32, i32* [[UB_ADDR]], align 4, [[DBG18]]
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, i32* [[UB_ADDR]], align 4, [[DBG18]]
; CHECK-NEXT:    [[TMP3:%.*]] = load i32, i32* [[STEP_ADDR]], align 4, [[DBG18]]
; CHECK-NEXT:    [[TMP4:%.*]] = alloca %nanos6_task_args_signed_loop_sge0*, align 8, [[DBG18]]
; CHECK-NEXT:    [[TMP5:%.*]] = alloca i8*, align 8, [[DBG18]]
; CHECK-NEXT:    [[NUM_DEPS:%.*]] = alloca i64, align 8, [[DBG18]]
; CHECK-NEXT:    br label [[FINAL_COND:%.*]], [[DBG18]]
; CHECK:       codeRepl:
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast %nanos6_task_args_signed_loop_sge0** [[TMP4]] to i8**, [[DBG18]]
; CHECK-NEXT:    store i64 0, i64* [[NUM_DEPS]], align 4, [[DBG18]]
; CHECK-NEXT:    [[TMP7:%.*]] = load i64, i64* [[NUM_DEPS]], align 4, [[DBG18]]
; CHECK-NEXT:    [[TMP8:%.*]] = sub i32 [[TMP2]], [[TMP1]], [[DBG18]]
; CHECK-NEXT:    [[TMP9:%.*]] = sdiv i32 [[TMP8]], [[TMP3]], [[DBG18]]
; CHECK-NEXT:    [[TMP10:%.*]] = add i32 [[TMP9]], 1, [[DBG18]]
; CHECK-NEXT:    [[TMP11:%.*]] = sext i32 [[TMP10]] to i64, [[DBG18]]
; CHECK-NEXT:    call void @nanos6_create_loop(%nanos6_task_info_t* @task_info_var_signed_loop_sge0, %nanos6_task_invocation_info_t* @task_invocation_info_signed_loop_sge0, i64 32, i8** [[TMP6]], i8** [[TMP5]], i64 8, i64 [[TMP7]], i64 0, i64 [[TMP11]], i64 0, i64 0), [[DBG18]]
; CHECK-NEXT:    [[TMP12:%.*]] = load %nanos6_task_args_signed_loop_sge0*, %nanos6_task_args_signed_loop_sge0** [[TMP4]], align 8, [[DBG18]]
; CHECK-NEXT:    [[TMP13:%.*]] = bitcast %nanos6_task_args_signed_loop_sge0* [[TMP12]] to i8*, [[DBG18]]
; CHECK-NEXT:    [[ARGS_END:%.*]] = getelementptr i8, i8* [[TMP13]], i64 32, [[DBG18]]
; CHECK-NEXT:    [[GEP_UB_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SGE0:%.*]], %nanos6_task_args_signed_loop_sge0* [[TMP12]], i32 0, i32 1, [[DBG18]]
; CHECK-NEXT:    [[TMP14:%.*]] = bitcast i32* [[GEP_UB_ADDR]] to i8*, [[DBG18]]
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i32* [[UB_ADDR]] to i8*, [[DBG18]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP14]], i8* align 4 [[TMP15]], i64 4, i1 false), [[DBG18]]
; CHECK-NEXT:    [[GEP_STEP_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SGE0]], %nanos6_task_args_signed_loop_sge0* [[TMP12]], i32 0, i32 2, [[DBG18]]
; CHECK-NEXT:    [[TMP16:%.*]] = bitcast i32* [[GEP_STEP_ADDR]] to i8*, [[DBG18]]
; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i32* [[STEP_ADDR]] to i8*, [[DBG18]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP16]], i8* align 4 [[TMP17]], i64 4, i1 false), [[DBG18]]
; CHECK-NEXT:    [[CAPT_GEP_:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SGE0]], %nanos6_task_args_signed_loop_sge0* [[TMP12]], i32 0, i32 3, [[DBG18]]
; CHECK-NEXT:    store i32 [[TMP1]], i32* [[CAPT_GEP_]], align 4, [[DBG18]]
; CHECK-NEXT:    [[CAPT_GEP_6:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SGE0]], %nanos6_task_args_signed_loop_sge0* [[TMP12]], i32 0, i32 4, [[DBG18]]
; CHECK-NEXT:    store i32 [[TMP2]], i32* [[CAPT_GEP_6]], align 4, [[DBG18]]
; CHECK-NEXT:    [[CAPT_GEP_7:%.*]] = getelementptr [[NANOS6_TASK_ARGS_SIGNED_LOOP_SGE0]], %nanos6_task_args_signed_loop_sge0* [[TMP12]], i32 0, i32 5, [[DBG18]]
; CHECK-NEXT:    store i32 [[TMP3]], i32* [[CAPT_GEP_7]], align 4, [[DBG18]]
; CHECK-NEXT:    [[TMP18:%.*]] = load i8*, i8** [[TMP5]], align 8, [[DBG18]]
; CHECK-NEXT:    call void @nanos6_submit_task(i8* [[TMP18]]), [[DBG18]]
; CHECK-NEXT:    br label [[FINAL_END:%.*]], [[DBG18]]
; CHECK:       final.end:
; CHECK-NEXT:    ret void, [[DBG19:!dbg !.*]]
; CHECK:       final.then:
; CHECK-NEXT:    store i32 [[TMP1]], i32* [[I]], align 4, [[DBG18]]
; CHECK-NEXT:    br label [[FOR_COND:%.*]], [[DBG18]]
; CHECK:       for.cond:
; CHECK-NEXT:    [[TMP19:%.*]] = load i32, i32* [[I]], align 4, [[DBG18]]
; CHECK-NEXT:    [[TMP20:%.*]] = icmp sge i32 [[TMP19]], [[TMP2]], [[DBG18]]
; CHECK-NEXT:    br i1 [[TMP20]], label [[FOR_BODY:%.*]], label [[FINAL_END]], [[DBG18]]
; CHECK:       for.body:
; CHECK-NEXT:    br label [[FOR_INCR:%.*]], [[DBG19]]
; CHECK:       for.incr:
; CHECK-NEXT:    [[TMP21:%.*]] = load i32, i32* [[I]], align 4, [[DBG18]]
; CHECK-NEXT:    [[TMP22:%.*]] = add i32 [[TMP21]], [[TMP3]], [[DBG18]]
; CHECK-NEXT:    store i32 [[TMP22]], i32* [[I]], align 4, [[DBG18]]
; CHECK-NEXT:    br label [[FOR_COND]], [[DBG18]]
; CHECK:       final.cond:
; CHECK-NEXT:    [[TMP23:%.*]] = call i32 @nanos6_in_final(), [[DBG18]]
; CHECK-NEXT:    [[TMP24:%.*]] = icmp ne i32 [[TMP23]], 0, [[DBG18]]
; CHECK-NEXT:    br i1 [[TMP24]], label [[FINAL_THEN:%.*]], label [[CODEREPL:%.*]], [[DBG18]]
;
entry:
  %lb.addr = alloca i32, align 4
  %ub.addr = alloca i32, align 4
  %step.addr = alloca i32, align 4
  %i = alloca i32, align 4
  store i32 %lb, i32* %lb.addr, align 4
  store i32 %ub, i32* %ub.addr, align 4
  store i32 %step, i32* %step.addr, align 4
  %0 = load i32, i32* %ub.addr, align 4, !dbg !18
  store i32 %0, i32* %i, align 4, !dbg !18
  %1 = load i32, i32* %ub.addr, align 4, !dbg !18
  %2 = load i32, i32* %ub.addr, align 4, !dbg !18
  %3 = load i32, i32* %step.addr, align 4, !dbg !18
  %4 = call token @llvm.directive.region.entry() [ "DIR.OSS"([9 x i8] c"TASK.FOR\00"), "QUAL.OSS.PRIVATE"(i32* %i), "QUAL.OSS.FIRSTPRIVATE"(i32* %ub.addr), "QUAL.OSS.FIRSTPRIVATE"(i32* %step.addr), "QUAL.OSS.LOOP.IND.VAR"(i32* %i), "QUAL.OSS.LOOP.LOWER.BOUND"(i32 %1), "QUAL.OSS.LOOP.UPPER.BOUND"(i32 %2), "QUAL.OSS.LOOP.STEP"(i32 %3), "QUAL.OSS.LOOP.TYPE"(i64 3, i64 1, i64 1, i64 1, i64 1), "QUAL.OSS.CAPTURED"(i32 %1, i32 %2, i32 %3) ], !dbg !18
  call void @llvm.directive.region.exit(token %4), !dbg !18
  ret void, !dbg !19
}

; Function Attrs: noinline nounwind optnone
define void @unsigned_loop_slt(i32 %lb, i32 %ub, i32 %step) #0 !dbg !20 {
; CHECK-LABEL: @unsigned_loop_slt(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[LB_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[UB_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[STEP_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[I:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store i32 [[LB:%.*]], i32* [[LB_ADDR]], align 4
; CHECK-NEXT:    store i32 [[UB:%.*]], i32* [[UB_ADDR]], align 4
; CHECK-NEXT:    store i32 [[STEP:%.*]], i32* [[STEP_ADDR]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, i32* [[LB_ADDR]], align 4, [[DBG21:!dbg !.*]]
; CHECK-NEXT:    store i32 [[TMP0]], i32* [[I]], align 4, [[DBG21]]
; CHECK-NEXT:    [[TMP1:%.*]] = load i32, i32* [[LB_ADDR]], align 4, [[DBG21]]
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, i32* [[UB_ADDR]], align 4, [[DBG21]]
; CHECK-NEXT:    [[TMP3:%.*]] = load i32, i32* [[STEP_ADDR]], align 4, [[DBG21]]
; CHECK-NEXT:    [[TMP4:%.*]] = alloca %nanos6_task_args_unsigned_loop_slt0*, align 8, [[DBG21]]
; CHECK-NEXT:    [[TMP5:%.*]] = alloca i8*, align 8, [[DBG21]]
; CHECK-NEXT:    [[NUM_DEPS:%.*]] = alloca i64, align 8, [[DBG21]]
; CHECK-NEXT:    br label [[FINAL_COND:%.*]], [[DBG21]]
; CHECK:       codeRepl:
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast %nanos6_task_args_unsigned_loop_slt0** [[TMP4]] to i8**, [[DBG21]]
; CHECK-NEXT:    store i64 0, i64* [[NUM_DEPS]], align 4, [[DBG21]]
; CHECK-NEXT:    [[TMP7:%.*]] = load i64, i64* [[NUM_DEPS]], align 4, [[DBG21]]
; CHECK-NEXT:    [[TMP8:%.*]] = sub i32 [[TMP2]], [[TMP1]], [[DBG21]]
; CHECK-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP8]], 1, [[DBG21]]
; CHECK-NEXT:    [[TMP10:%.*]] = udiv i32 [[TMP9]], [[TMP3]], [[DBG21]]
; CHECK-NEXT:    [[TMP11:%.*]] = add i32 [[TMP10]], 1, [[DBG21]]
; CHECK-NEXT:    [[TMP12:%.*]] = zext i32 [[TMP11]] to i64, [[DBG21]]
; CHECK-NEXT:    call void @nanos6_create_loop(%nanos6_task_info_t* @task_info_var_unsigned_loop_slt0, %nanos6_task_invocation_info_t* @task_invocation_info_unsigned_loop_slt0, i64 32, i8** [[TMP6]], i8** [[TMP5]], i64 8, i64 [[TMP7]], i64 0, i64 [[TMP12]], i64 0, i64 0), [[DBG21]]
; CHECK-NEXT:    [[TMP13:%.*]] = load %nanos6_task_args_unsigned_loop_slt0*, %nanos6_task_args_unsigned_loop_slt0** [[TMP4]], align 8, [[DBG21]]
; CHECK-NEXT:    [[TMP14:%.*]] = bitcast %nanos6_task_args_unsigned_loop_slt0* [[TMP13]] to i8*, [[DBG21]]
; CHECK-NEXT:    [[ARGS_END:%.*]] = getelementptr i8, i8* [[TMP14]], i64 32, [[DBG21]]
; CHECK-NEXT:    [[GEP_LB_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SLT0:%.*]], %nanos6_task_args_unsigned_loop_slt0* [[TMP13]], i32 0, i32 1, [[DBG21]]
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i32* [[GEP_LB_ADDR]] to i8*, [[DBG21]]
; CHECK-NEXT:    [[TMP16:%.*]] = bitcast i32* [[LB_ADDR]] to i8*, [[DBG21]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP15]], i8* align 4 [[TMP16]], i64 4, i1 false), [[DBG21]]
; CHECK-NEXT:    [[GEP_UB_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SLT0]], %nanos6_task_args_unsigned_loop_slt0* [[TMP13]], i32 0, i32 2, [[DBG21]]
; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i32* [[GEP_UB_ADDR]] to i8*, [[DBG21]]
; CHECK-NEXT:    [[TMP18:%.*]] = bitcast i32* [[UB_ADDR]] to i8*, [[DBG21]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP17]], i8* align 4 [[TMP18]], i64 4, i1 false), [[DBG21]]
; CHECK-NEXT:    [[GEP_STEP_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SLT0]], %nanos6_task_args_unsigned_loop_slt0* [[TMP13]], i32 0, i32 3, [[DBG21]]
; CHECK-NEXT:    [[TMP19:%.*]] = bitcast i32* [[GEP_STEP_ADDR]] to i8*, [[DBG21]]
; CHECK-NEXT:    [[TMP20:%.*]] = bitcast i32* [[STEP_ADDR]] to i8*, [[DBG21]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP19]], i8* align 4 [[TMP20]], i64 4, i1 false), [[DBG21]]
; CHECK-NEXT:    [[CAPT_GEP_:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SLT0]], %nanos6_task_args_unsigned_loop_slt0* [[TMP13]], i32 0, i32 4, [[DBG21]]
; CHECK-NEXT:    store i32 [[TMP1]], i32* [[CAPT_GEP_]], align 4, [[DBG21]]
; CHECK-NEXT:    [[CAPT_GEP_6:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SLT0]], %nanos6_task_args_unsigned_loop_slt0* [[TMP13]], i32 0, i32 5, [[DBG21]]
; CHECK-NEXT:    store i32 [[TMP2]], i32* [[CAPT_GEP_6]], align 4, [[DBG21]]
; CHECK-NEXT:    [[CAPT_GEP_7:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SLT0]], %nanos6_task_args_unsigned_loop_slt0* [[TMP13]], i32 0, i32 6, [[DBG21]]
; CHECK-NEXT:    store i32 [[TMP3]], i32* [[CAPT_GEP_7]], align 4, [[DBG21]]
; CHECK-NEXT:    [[TMP21:%.*]] = load i8*, i8** [[TMP5]], align 8, [[DBG21]]
; CHECK-NEXT:    call void @nanos6_submit_task(i8* [[TMP21]]), [[DBG21]]
; CHECK-NEXT:    br label [[FINAL_END:%.*]], [[DBG21]]
; CHECK:       final.end:
; CHECK-NEXT:    ret void, [[DBG22:!dbg !.*]]
; CHECK:       final.then:
; CHECK-NEXT:    store i32 [[TMP1]], i32* [[I]], align 4, [[DBG21]]
; CHECK-NEXT:    br label [[FOR_COND:%.*]], [[DBG21]]
; CHECK:       for.cond:
; CHECK-NEXT:    [[TMP22:%.*]] = load i32, i32* [[I]], align 4, [[DBG21]]
; CHECK-NEXT:    [[TMP23:%.*]] = icmp ult i32 [[TMP22]], [[TMP2]], [[DBG21]]
; CHECK-NEXT:    br i1 [[TMP23]], label [[FOR_BODY:%.*]], label [[FINAL_END]], [[DBG21]]
; CHECK:       for.body:
; CHECK-NEXT:    br label [[FOR_INCR:%.*]], [[DBG22]]
; CHECK:       for.incr:
; CHECK-NEXT:    [[TMP24:%.*]] = load i32, i32* [[I]], align 4, [[DBG21]]
; CHECK-NEXT:    [[TMP25:%.*]] = add i32 [[TMP24]], [[TMP3]], [[DBG21]]
; CHECK-NEXT:    store i32 [[TMP25]], i32* [[I]], align 4, [[DBG21]]
; CHECK-NEXT:    br label [[FOR_COND]], [[DBG21]]
; CHECK:       final.cond:
; CHECK-NEXT:    [[TMP26:%.*]] = call i32 @nanos6_in_final(), [[DBG21]]
; CHECK-NEXT:    [[TMP27:%.*]] = icmp ne i32 [[TMP26]], 0, [[DBG21]]
; CHECK-NEXT:    br i1 [[TMP27]], label [[FINAL_THEN:%.*]], label [[CODEREPL:%.*]], [[DBG21]]
;
entry:
  %lb.addr = alloca i32, align 4
  %ub.addr = alloca i32, align 4
  %step.addr = alloca i32, align 4
  %i = alloca i32, align 4
  store i32 %lb, i32* %lb.addr, align 4
  store i32 %ub, i32* %ub.addr, align 4
  store i32 %step, i32* %step.addr, align 4
  %0 = load i32, i32* %lb.addr, align 4, !dbg !21
  store i32 %0, i32* %i, align 4, !dbg !21
  %1 = load i32, i32* %lb.addr, align 4, !dbg !21
  %2 = load i32, i32* %ub.addr, align 4, !dbg !21
  %3 = load i32, i32* %step.addr, align 4, !dbg !21
  %4 = call token @llvm.directive.region.entry() [ "DIR.OSS"([9 x i8] c"TASK.FOR\00"), "QUAL.OSS.PRIVATE"(i32* %i), "QUAL.OSS.FIRSTPRIVATE"(i32* %lb.addr), "QUAL.OSS.FIRSTPRIVATE"(i32* %ub.addr), "QUAL.OSS.FIRSTPRIVATE"(i32* %step.addr), "QUAL.OSS.LOOP.IND.VAR"(i32* %i), "QUAL.OSS.LOOP.LOWER.BOUND"(i32 %1), "QUAL.OSS.LOOP.UPPER.BOUND"(i32 %2), "QUAL.OSS.LOOP.STEP"(i32 %3), "QUAL.OSS.LOOP.TYPE"(i64 0, i64 0, i64 0, i64 0, i64 0), "QUAL.OSS.CAPTURED"(i32 %1, i32 %2, i32 %3) ], !dbg !21
  call void @llvm.directive.region.exit(token %4), !dbg !21
  ret void, !dbg !22
}

; Function Attrs: noinline nounwind optnone
define void @unsigned_loop_sle(i32 %lb, i32 %ub, i32 %step) #0 !dbg !23 {
; CHECK-LABEL: @unsigned_loop_sle(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[LB_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[UB_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[STEP_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[I:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store i32 [[LB:%.*]], i32* [[LB_ADDR]], align 4
; CHECK-NEXT:    store i32 [[UB:%.*]], i32* [[UB_ADDR]], align 4
; CHECK-NEXT:    store i32 [[STEP:%.*]], i32* [[STEP_ADDR]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, i32* [[LB_ADDR]], align 4, [[DBG24:!dbg !.*]]
; CHECK-NEXT:    store i32 [[TMP0]], i32* [[I]], align 4, [[DBG24]]
; CHECK-NEXT:    [[TMP1:%.*]] = load i32, i32* [[LB_ADDR]], align 4, [[DBG24]]
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, i32* [[UB_ADDR]], align 4, [[DBG24]]
; CHECK-NEXT:    [[TMP3:%.*]] = load i32, i32* [[STEP_ADDR]], align 4, [[DBG24]]
; CHECK-NEXT:    [[TMP4:%.*]] = alloca %nanos6_task_args_unsigned_loop_sle0*, align 8, [[DBG24]]
; CHECK-NEXT:    [[TMP5:%.*]] = alloca i8*, align 8, [[DBG24]]
; CHECK-NEXT:    [[NUM_DEPS:%.*]] = alloca i64, align 8, [[DBG24]]
; CHECK-NEXT:    br label [[FINAL_COND:%.*]], [[DBG24]]
; CHECK:       codeRepl:
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast %nanos6_task_args_unsigned_loop_sle0** [[TMP4]] to i8**, [[DBG24]]
; CHECK-NEXT:    store i64 0, i64* [[NUM_DEPS]], align 4, [[DBG24]]
; CHECK-NEXT:    [[TMP7:%.*]] = load i64, i64* [[NUM_DEPS]], align 4, [[DBG24]]
; CHECK-NEXT:    [[TMP8:%.*]] = sub i32 [[TMP2]], [[TMP1]], [[DBG24]]
; CHECK-NEXT:    [[TMP9:%.*]] = udiv i32 [[TMP8]], [[TMP3]], [[DBG24]]
; CHECK-NEXT:    [[TMP10:%.*]] = add i32 [[TMP9]], 1, [[DBG24]]
; CHECK-NEXT:    [[TMP11:%.*]] = zext i32 [[TMP10]] to i64, [[DBG24]]
; CHECK-NEXT:    call void @nanos6_create_loop(%nanos6_task_info_t* @task_info_var_unsigned_loop_sle0, %nanos6_task_invocation_info_t* @task_invocation_info_unsigned_loop_sle0, i64 32, i8** [[TMP6]], i8** [[TMP5]], i64 8, i64 [[TMP7]], i64 0, i64 [[TMP11]], i64 0, i64 0), [[DBG24]]
; CHECK-NEXT:    [[TMP12:%.*]] = load %nanos6_task_args_unsigned_loop_sle0*, %nanos6_task_args_unsigned_loop_sle0** [[TMP4]], align 8, [[DBG24]]
; CHECK-NEXT:    [[TMP13:%.*]] = bitcast %nanos6_task_args_unsigned_loop_sle0* [[TMP12]] to i8*, [[DBG24]]
; CHECK-NEXT:    [[ARGS_END:%.*]] = getelementptr i8, i8* [[TMP13]], i64 32, [[DBG24]]
; CHECK-NEXT:    [[GEP_LB_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SLE0:%.*]], %nanos6_task_args_unsigned_loop_sle0* [[TMP12]], i32 0, i32 1, [[DBG24]]
; CHECK-NEXT:    [[TMP14:%.*]] = bitcast i32* [[GEP_LB_ADDR]] to i8*, [[DBG24]]
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i32* [[LB_ADDR]] to i8*, [[DBG24]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP14]], i8* align 4 [[TMP15]], i64 4, i1 false), [[DBG24]]
; CHECK-NEXT:    [[GEP_UB_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SLE0]], %nanos6_task_args_unsigned_loop_sle0* [[TMP12]], i32 0, i32 2, [[DBG24]]
; CHECK-NEXT:    [[TMP16:%.*]] = bitcast i32* [[GEP_UB_ADDR]] to i8*, [[DBG24]]
; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i32* [[UB_ADDR]] to i8*, [[DBG24]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP16]], i8* align 4 [[TMP17]], i64 4, i1 false), [[DBG24]]
; CHECK-NEXT:    [[GEP_STEP_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SLE0]], %nanos6_task_args_unsigned_loop_sle0* [[TMP12]], i32 0, i32 3, [[DBG24]]
; CHECK-NEXT:    [[TMP18:%.*]] = bitcast i32* [[GEP_STEP_ADDR]] to i8*, [[DBG24]]
; CHECK-NEXT:    [[TMP19:%.*]] = bitcast i32* [[STEP_ADDR]] to i8*, [[DBG24]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP18]], i8* align 4 [[TMP19]], i64 4, i1 false), [[DBG24]]
; CHECK-NEXT:    [[CAPT_GEP_:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SLE0]], %nanos6_task_args_unsigned_loop_sle0* [[TMP12]], i32 0, i32 4, [[DBG24]]
; CHECK-NEXT:    store i32 [[TMP1]], i32* [[CAPT_GEP_]], align 4, [[DBG24]]
; CHECK-NEXT:    [[CAPT_GEP_6:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SLE0]], %nanos6_task_args_unsigned_loop_sle0* [[TMP12]], i32 0, i32 5, [[DBG24]]
; CHECK-NEXT:    store i32 [[TMP2]], i32* [[CAPT_GEP_6]], align 4, [[DBG24]]
; CHECK-NEXT:    [[CAPT_GEP_7:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SLE0]], %nanos6_task_args_unsigned_loop_sle0* [[TMP12]], i32 0, i32 6, [[DBG24]]
; CHECK-NEXT:    store i32 [[TMP3]], i32* [[CAPT_GEP_7]], align 4, [[DBG24]]
; CHECK-NEXT:    [[TMP20:%.*]] = load i8*, i8** [[TMP5]], align 8, [[DBG24]]
; CHECK-NEXT:    call void @nanos6_submit_task(i8* [[TMP20]]), [[DBG24]]
; CHECK-NEXT:    br label [[FINAL_END:%.*]], [[DBG24]]
; CHECK:       final.end:
; CHECK-NEXT:    ret void, [[DBG25:!dbg !.*]]
; CHECK:       final.then:
; CHECK-NEXT:    store i32 [[TMP1]], i32* [[I]], align 4, [[DBG24]]
; CHECK-NEXT:    br label [[FOR_COND:%.*]], [[DBG24]]
; CHECK:       for.cond:
; CHECK-NEXT:    [[TMP21:%.*]] = load i32, i32* [[I]], align 4, [[DBG24]]
; CHECK-NEXT:    [[TMP22:%.*]] = icmp ule i32 [[TMP21]], [[TMP2]], [[DBG24]]
; CHECK-NEXT:    br i1 [[TMP22]], label [[FOR_BODY:%.*]], label [[FINAL_END]], [[DBG24]]
; CHECK:       for.body:
; CHECK-NEXT:    br label [[FOR_INCR:%.*]], [[DBG25]]
; CHECK:       for.incr:
; CHECK-NEXT:    [[TMP23:%.*]] = load i32, i32* [[I]], align 4, [[DBG24]]
; CHECK-NEXT:    [[TMP24:%.*]] = add i32 [[TMP23]], [[TMP3]], [[DBG24]]
; CHECK-NEXT:    store i32 [[TMP24]], i32* [[I]], align 4, [[DBG24]]
; CHECK-NEXT:    br label [[FOR_COND]], [[DBG24]]
; CHECK:       final.cond:
; CHECK-NEXT:    [[TMP25:%.*]] = call i32 @nanos6_in_final(), [[DBG24]]
; CHECK-NEXT:    [[TMP26:%.*]] = icmp ne i32 [[TMP25]], 0, [[DBG24]]
; CHECK-NEXT:    br i1 [[TMP26]], label [[FINAL_THEN:%.*]], label [[CODEREPL:%.*]], [[DBG24]]
;
entry:
  %lb.addr = alloca i32, align 4
  %ub.addr = alloca i32, align 4
  %step.addr = alloca i32, align 4
  %i = alloca i32, align 4
  store i32 %lb, i32* %lb.addr, align 4
  store i32 %ub, i32* %ub.addr, align 4
  store i32 %step, i32* %step.addr, align 4
  %0 = load i32, i32* %lb.addr, align 4, !dbg !24
  store i32 %0, i32* %i, align 4, !dbg !24
  %1 = load i32, i32* %lb.addr, align 4, !dbg !24
  %2 = load i32, i32* %ub.addr, align 4, !dbg !24
  %3 = load i32, i32* %step.addr, align 4, !dbg !24
  %4 = call token @llvm.directive.region.entry() [ "DIR.OSS"([9 x i8] c"TASK.FOR\00"), "QUAL.OSS.PRIVATE"(i32* %i), "QUAL.OSS.FIRSTPRIVATE"(i32* %lb.addr), "QUAL.OSS.FIRSTPRIVATE"(i32* %ub.addr), "QUAL.OSS.FIRSTPRIVATE"(i32* %step.addr), "QUAL.OSS.LOOP.IND.VAR"(i32* %i), "QUAL.OSS.LOOP.LOWER.BOUND"(i32 %1), "QUAL.OSS.LOOP.UPPER.BOUND"(i32 %2), "QUAL.OSS.LOOP.STEP"(i32 %3), "QUAL.OSS.LOOP.TYPE"(i64 1, i64 0, i64 0, i64 0, i64 0), "QUAL.OSS.CAPTURED"(i32 %1, i32 %2, i32 %3) ], !dbg !24
  call void @llvm.directive.region.exit(token %4), !dbg !24
  ret void, !dbg !25
}

; Function Attrs: noinline nounwind optnone
define void @unsigned_loop_sgt(i32 %lb, i32 %ub, i32 %step) #0 !dbg !26 {
; CHECK-LABEL: @unsigned_loop_sgt(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[LB_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[UB_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[STEP_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[I:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store i32 [[LB:%.*]], i32* [[LB_ADDR]], align 4
; CHECK-NEXT:    store i32 [[UB:%.*]], i32* [[UB_ADDR]], align 4
; CHECK-NEXT:    store i32 [[STEP:%.*]], i32* [[STEP_ADDR]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, i32* [[UB_ADDR]], align 4, [[DBG27:!dbg !.*]]
; CHECK-NEXT:    store i32 [[TMP0]], i32* [[I]], align 4, [[DBG27]]
; CHECK-NEXT:    [[TMP1:%.*]] = load i32, i32* [[UB_ADDR]], align 4, [[DBG27]]
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, i32* [[UB_ADDR]], align 4, [[DBG27]]
; CHECK-NEXT:    [[TMP3:%.*]] = load i32, i32* [[STEP_ADDR]], align 4, [[DBG27]]
; CHECK-NEXT:    [[TMP4:%.*]] = alloca %nanos6_task_args_unsigned_loop_sgt0*, align 8, [[DBG27]]
; CHECK-NEXT:    [[TMP5:%.*]] = alloca i8*, align 8, [[DBG27]]
; CHECK-NEXT:    [[NUM_DEPS:%.*]] = alloca i64, align 8, [[DBG27]]
; CHECK-NEXT:    br label [[FINAL_COND:%.*]], [[DBG27]]
; CHECK:       codeRepl:
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast %nanos6_task_args_unsigned_loop_sgt0** [[TMP4]] to i8**, [[DBG27]]
; CHECK-NEXT:    store i64 0, i64* [[NUM_DEPS]], align 4, [[DBG27]]
; CHECK-NEXT:    [[TMP7:%.*]] = load i64, i64* [[NUM_DEPS]], align 4, [[DBG27]]
; CHECK-NEXT:    [[TMP8:%.*]] = sub i32 [[TMP2]], [[TMP1]], [[DBG27]]
; CHECK-NEXT:    [[TMP9:%.*]] = add i32 [[TMP8]], 1, [[DBG27]]
; CHECK-NEXT:    [[TMP10:%.*]] = udiv i32 [[TMP9]], [[TMP3]], [[DBG27]]
; CHECK-NEXT:    [[TMP11:%.*]] = add i32 [[TMP10]], 1, [[DBG27]]
; CHECK-NEXT:    [[TMP12:%.*]] = zext i32 [[TMP11]] to i64, [[DBG27]]
; CHECK-NEXT:    call void @nanos6_create_loop(%nanos6_task_info_t* @task_info_var_unsigned_loop_sgt0, %nanos6_task_invocation_info_t* @task_invocation_info_unsigned_loop_sgt0, i64 32, i8** [[TMP6]], i8** [[TMP5]], i64 8, i64 [[TMP7]], i64 0, i64 [[TMP12]], i64 0, i64 0), [[DBG27]]
; CHECK-NEXT:    [[TMP13:%.*]] = load %nanos6_task_args_unsigned_loop_sgt0*, %nanos6_task_args_unsigned_loop_sgt0** [[TMP4]], align 8, [[DBG27]]
; CHECK-NEXT:    [[TMP14:%.*]] = bitcast %nanos6_task_args_unsigned_loop_sgt0* [[TMP13]] to i8*, [[DBG27]]
; CHECK-NEXT:    [[ARGS_END:%.*]] = getelementptr i8, i8* [[TMP14]], i64 32, [[DBG27]]
; CHECK-NEXT:    [[GEP_UB_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SGT0:%.*]], %nanos6_task_args_unsigned_loop_sgt0* [[TMP13]], i32 0, i32 1, [[DBG27]]
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i32* [[GEP_UB_ADDR]] to i8*, [[DBG27]]
; CHECK-NEXT:    [[TMP16:%.*]] = bitcast i32* [[UB_ADDR]] to i8*, [[DBG27]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP15]], i8* align 4 [[TMP16]], i64 4, i1 false), [[DBG27]]
; CHECK-NEXT:    [[GEP_STEP_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SGT0]], %nanos6_task_args_unsigned_loop_sgt0* [[TMP13]], i32 0, i32 2, [[DBG27]]
; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i32* [[GEP_STEP_ADDR]] to i8*, [[DBG27]]
; CHECK-NEXT:    [[TMP18:%.*]] = bitcast i32* [[STEP_ADDR]] to i8*, [[DBG27]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP17]], i8* align 4 [[TMP18]], i64 4, i1 false), [[DBG27]]
; CHECK-NEXT:    [[CAPT_GEP_:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SGT0]], %nanos6_task_args_unsigned_loop_sgt0* [[TMP13]], i32 0, i32 3, [[DBG27]]
; CHECK-NEXT:    store i32 [[TMP1]], i32* [[CAPT_GEP_]], align 4, [[DBG27]]
; CHECK-NEXT:    [[CAPT_GEP_6:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SGT0]], %nanos6_task_args_unsigned_loop_sgt0* [[TMP13]], i32 0, i32 4, [[DBG27]]
; CHECK-NEXT:    store i32 [[TMP2]], i32* [[CAPT_GEP_6]], align 4, [[DBG27]]
; CHECK-NEXT:    [[CAPT_GEP_7:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SGT0]], %nanos6_task_args_unsigned_loop_sgt0* [[TMP13]], i32 0, i32 5, [[DBG27]]
; CHECK-NEXT:    store i32 [[TMP3]], i32* [[CAPT_GEP_7]], align 4, [[DBG27]]
; CHECK-NEXT:    [[TMP19:%.*]] = load i8*, i8** [[TMP5]], align 8, [[DBG27]]
; CHECK-NEXT:    call void @nanos6_submit_task(i8* [[TMP19]]), [[DBG27]]
; CHECK-NEXT:    br label [[FINAL_END:%.*]], [[DBG27]]
; CHECK:       final.end:
; CHECK-NEXT:    ret void, [[DBG28:!dbg !.*]]
; CHECK:       final.then:
; CHECK-NEXT:    store i32 [[TMP1]], i32* [[I]], align 4, [[DBG27]]
; CHECK-NEXT:    br label [[FOR_COND:%.*]], [[DBG27]]
; CHECK:       for.cond:
; CHECK-NEXT:    [[TMP20:%.*]] = load i32, i32* [[I]], align 4, [[DBG27]]
; CHECK-NEXT:    [[TMP21:%.*]] = icmp ugt i32 [[TMP20]], [[TMP2]], [[DBG27]]
; CHECK-NEXT:    br i1 [[TMP21]], label [[FOR_BODY:%.*]], label [[FINAL_END]], [[DBG27]]
; CHECK:       for.body:
; CHECK-NEXT:    br label [[FOR_INCR:%.*]], [[DBG28]]
; CHECK:       for.incr:
; CHECK-NEXT:    [[TMP22:%.*]] = load i32, i32* [[I]], align 4, [[DBG27]]
; CHECK-NEXT:    [[TMP23:%.*]] = add i32 [[TMP22]], [[TMP3]], [[DBG27]]
; CHECK-NEXT:    store i32 [[TMP23]], i32* [[I]], align 4, [[DBG27]]
; CHECK-NEXT:    br label [[FOR_COND]], [[DBG27]]
; CHECK:       final.cond:
; CHECK-NEXT:    [[TMP24:%.*]] = call i32 @nanos6_in_final(), [[DBG27]]
; CHECK-NEXT:    [[TMP25:%.*]] = icmp ne i32 [[TMP24]], 0, [[DBG27]]
; CHECK-NEXT:    br i1 [[TMP25]], label [[FINAL_THEN:%.*]], label [[CODEREPL:%.*]], [[DBG27]]
;
entry:
  %lb.addr = alloca i32, align 4
  %ub.addr = alloca i32, align 4
  %step.addr = alloca i32, align 4
  %i = alloca i32, align 4
  store i32 %lb, i32* %lb.addr, align 4
  store i32 %ub, i32* %ub.addr, align 4
  store i32 %step, i32* %step.addr, align 4
  %0 = load i32, i32* %ub.addr, align 4, !dbg !27
  store i32 %0, i32* %i, align 4, !dbg !27
  %1 = load i32, i32* %ub.addr, align 4, !dbg !27
  %2 = load i32, i32* %ub.addr, align 4, !dbg !27
  %3 = load i32, i32* %step.addr, align 4, !dbg !27
  %4 = call token @llvm.directive.region.entry() [ "DIR.OSS"([9 x i8] c"TASK.FOR\00"), "QUAL.OSS.PRIVATE"(i32* %i), "QUAL.OSS.FIRSTPRIVATE"(i32* %ub.addr), "QUAL.OSS.FIRSTPRIVATE"(i32* %step.addr), "QUAL.OSS.LOOP.IND.VAR"(i32* %i), "QUAL.OSS.LOOP.LOWER.BOUND"(i32 %1), "QUAL.OSS.LOOP.UPPER.BOUND"(i32 %2), "QUAL.OSS.LOOP.STEP"(i32 %3), "QUAL.OSS.LOOP.TYPE"(i64 2, i64 0, i64 0, i64 0, i64 0), "QUAL.OSS.CAPTURED"(i32 %1, i32 %2, i32 %3) ], !dbg !27
  call void @llvm.directive.region.exit(token %4), !dbg !27
  ret void, !dbg !28
}

; Function Attrs: noinline nounwind optnone
define void @unsigned_loop_sge(i32 %lb, i32 %ub, i32 %step) #0 !dbg !29 {
; CHECK-LABEL: @unsigned_loop_sge(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[LB_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[UB_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[STEP_ADDR:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[I:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store i32 [[LB:%.*]], i32* [[LB_ADDR]], align 4
; CHECK-NEXT:    store i32 [[UB:%.*]], i32* [[UB_ADDR]], align 4
; CHECK-NEXT:    store i32 [[STEP:%.*]], i32* [[STEP_ADDR]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, i32* [[UB_ADDR]], align 4, [[DBG30:!dbg !.*]]
; CHECK-NEXT:    store i32 [[TMP0]], i32* [[I]], align 4, [[DBG30]]
; CHECK-NEXT:    [[TMP1:%.*]] = load i32, i32* [[UB_ADDR]], align 4, [[DBG30]]
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, i32* [[UB_ADDR]], align 4, [[DBG30]]
; CHECK-NEXT:    [[TMP3:%.*]] = load i32, i32* [[STEP_ADDR]], align 4, [[DBG30]]
; CHECK-NEXT:    [[TMP4:%.*]] = alloca %nanos6_task_args_unsigned_loop_sge0*, align 8, [[DBG30]]
; CHECK-NEXT:    [[TMP5:%.*]] = alloca i8*, align 8, [[DBG30]]
; CHECK-NEXT:    [[NUM_DEPS:%.*]] = alloca i64, align 8, [[DBG30]]
; CHECK-NEXT:    br label [[FINAL_COND:%.*]], [[DBG30]]
; CHECK:       codeRepl:
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast %nanos6_task_args_unsigned_loop_sge0** [[TMP4]] to i8**, [[DBG30]]
; CHECK-NEXT:    store i64 0, i64* [[NUM_DEPS]], align 4, [[DBG30]]
; CHECK-NEXT:    [[TMP7:%.*]] = load i64, i64* [[NUM_DEPS]], align 4, [[DBG30]]
; CHECK-NEXT:    [[TMP8:%.*]] = sub i32 [[TMP2]], [[TMP1]], [[DBG30]]
; CHECK-NEXT:    [[TMP9:%.*]] = udiv i32 [[TMP8]], [[TMP3]], [[DBG30]]
; CHECK-NEXT:    [[TMP10:%.*]] = add i32 [[TMP9]], 1, [[DBG30]]
; CHECK-NEXT:    [[TMP11:%.*]] = zext i32 [[TMP10]] to i64, [[DBG30]]
; CHECK-NEXT:    call void @nanos6_create_loop(%nanos6_task_info_t* @task_info_var_unsigned_loop_sge0, %nanos6_task_invocation_info_t* @task_invocation_info_unsigned_loop_sge0, i64 32, i8** [[TMP6]], i8** [[TMP5]], i64 8, i64 [[TMP7]], i64 0, i64 [[TMP11]], i64 0, i64 0), [[DBG30]]
; CHECK-NEXT:    [[TMP12:%.*]] = load %nanos6_task_args_unsigned_loop_sge0*, %nanos6_task_args_unsigned_loop_sge0** [[TMP4]], align 8, [[DBG30]]
; CHECK-NEXT:    [[TMP13:%.*]] = bitcast %nanos6_task_args_unsigned_loop_sge0* [[TMP12]] to i8*, [[DBG30]]
; CHECK-NEXT:    [[ARGS_END:%.*]] = getelementptr i8, i8* [[TMP13]], i64 32, [[DBG30]]
; CHECK-NEXT:    [[GEP_UB_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SGE0:%.*]], %nanos6_task_args_unsigned_loop_sge0* [[TMP12]], i32 0, i32 1, [[DBG30]]
; CHECK-NEXT:    [[TMP14:%.*]] = bitcast i32* [[GEP_UB_ADDR]] to i8*, [[DBG30]]
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i32* [[UB_ADDR]] to i8*, [[DBG30]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP14]], i8* align 4 [[TMP15]], i64 4, i1 false), [[DBG30]]
; CHECK-NEXT:    [[GEP_STEP_ADDR:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SGE0]], %nanos6_task_args_unsigned_loop_sge0* [[TMP12]], i32 0, i32 2, [[DBG30]]
; CHECK-NEXT:    [[TMP16:%.*]] = bitcast i32* [[GEP_STEP_ADDR]] to i8*, [[DBG30]]
; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i32* [[STEP_ADDR]] to i8*, [[DBG30]]
; CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 [[TMP16]], i8* align 4 [[TMP17]], i64 4, i1 false), [[DBG30]]
; CHECK-NEXT:    [[CAPT_GEP_:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SGE0]], %nanos6_task_args_unsigned_loop_sge0* [[TMP12]], i32 0, i32 3, [[DBG30]]
; CHECK-NEXT:    store i32 [[TMP1]], i32* [[CAPT_GEP_]], align 4, [[DBG30]]
; CHECK-NEXT:    [[CAPT_GEP_6:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SGE0]], %nanos6_task_args_unsigned_loop_sge0* [[TMP12]], i32 0, i32 4, [[DBG30]]
; CHECK-NEXT:    store i32 [[TMP2]], i32* [[CAPT_GEP_6]], align 4, [[DBG30]]
; CHECK-NEXT:    [[CAPT_GEP_7:%.*]] = getelementptr [[NANOS6_TASK_ARGS_UNSIGNED_LOOP_SGE0]], %nanos6_task_args_unsigned_loop_sge0* [[TMP12]], i32 0, i32 5, [[DBG30]]
; CHECK-NEXT:    store i32 [[TMP3]], i32* [[CAPT_GEP_7]], align 4, [[DBG30]]
; CHECK-NEXT:    [[TMP18:%.*]] = load i8*, i8** [[TMP5]], align 8, [[DBG30]]
; CHECK-NEXT:    call void @nanos6_submit_task(i8* [[TMP18]]), [[DBG30]]
; CHECK-NEXT:    br label [[FINAL_END:%.*]], [[DBG30]]
; CHECK:       final.end:
; CHECK-NEXT:    ret void, [[DBG31:!dbg !.*]]
; CHECK:       final.then:
; CHECK-NEXT:    store i32 [[TMP1]], i32* [[I]], align 4, [[DBG30]]
; CHECK-NEXT:    br label [[FOR_COND:%.*]], [[DBG30]]
; CHECK:       for.cond:
; CHECK-NEXT:    [[TMP19:%.*]] = load i32, i32* [[I]], align 4, [[DBG30]]
; CHECK-NEXT:    [[TMP20:%.*]] = icmp uge i32 [[TMP19]], [[TMP2]], [[DBG30]]
; CHECK-NEXT:    br i1 [[TMP20]], label [[FOR_BODY:%.*]], label [[FINAL_END]], [[DBG30]]
; CHECK:       for.body:
; CHECK-NEXT:    br label [[FOR_INCR:%.*]], [[DBG31]]
; CHECK:       for.incr:
; CHECK-NEXT:    [[TMP21:%.*]] = load i32, i32* [[I]], align 4, [[DBG30]]
; CHECK-NEXT:    [[TMP22:%.*]] = add i32 [[TMP21]], [[TMP3]], [[DBG30]]
; CHECK-NEXT:    store i32 [[TMP22]], i32* [[I]], align 4, [[DBG30]]
; CHECK-NEXT:    br label [[FOR_COND]], [[DBG30]]
; CHECK:       final.cond:
; CHECK-NEXT:    [[TMP23:%.*]] = call i32 @nanos6_in_final(), [[DBG30]]
; CHECK-NEXT:    [[TMP24:%.*]] = icmp ne i32 [[TMP23]], 0, [[DBG30]]
; CHECK-NEXT:    br i1 [[TMP24]], label [[FINAL_THEN:%.*]], label [[CODEREPL:%.*]], [[DBG30]]
;
entry:
  %lb.addr = alloca i32, align 4
  %ub.addr = alloca i32, align 4
  %step.addr = alloca i32, align 4
  %i = alloca i32, align 4
  store i32 %lb, i32* %lb.addr, align 4
  store i32 %ub, i32* %ub.addr, align 4
  store i32 %step, i32* %step.addr, align 4
  %0 = load i32, i32* %ub.addr, align 4, !dbg !30
  store i32 %0, i32* %i, align 4, !dbg !30
  %1 = load i32, i32* %ub.addr, align 4, !dbg !30
  %2 = load i32, i32* %ub.addr, align 4, !dbg !30
  %3 = load i32, i32* %step.addr, align 4, !dbg !30
  %4 = call token @llvm.directive.region.entry() [ "DIR.OSS"([9 x i8] c"TASK.FOR\00"), "QUAL.OSS.PRIVATE"(i32* %i), "QUAL.OSS.FIRSTPRIVATE"(i32* %ub.addr), "QUAL.OSS.FIRSTPRIVATE"(i32* %step.addr), "QUAL.OSS.LOOP.IND.VAR"(i32* %i), "QUAL.OSS.LOOP.LOWER.BOUND"(i32 %1), "QUAL.OSS.LOOP.UPPER.BOUND"(i32 %2), "QUAL.OSS.LOOP.STEP"(i32 %3), "QUAL.OSS.LOOP.TYPE"(i64 3, i64 0, i64 0, i64 0, i64 0), "QUAL.OSS.CAPTURED"(i32 %1, i32 %2, i32 %3) ], !dbg !30
  call void @llvm.directive.region.exit(token %4), !dbg !30
  ret void, !dbg !31
}

; Function Attrs: noinline nounwind optnone
define void @constants_loop() #0 !dbg !32 {
; CHECK-LABEL: @constants_loop(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[I:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store i32 0, i32* [[I]], align 4, [[DBG33:!dbg !.*]]
; CHECK-NEXT:    [[TMP0:%.*]] = alloca %nanos6_task_args_constants_loop0*, align 8, [[DBG33]]
; CHECK-NEXT:    [[TMP1:%.*]] = alloca i8*, align 8, [[DBG33]]
; CHECK-NEXT:    [[NUM_DEPS:%.*]] = alloca i64, align 8, [[DBG33]]
; CHECK-NEXT:    br label [[FINAL_COND:%.*]], [[DBG33]]
; CHECK:       codeRepl:
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast %nanos6_task_args_constants_loop0** [[TMP0]] to i8**, [[DBG33]]
; CHECK-NEXT:    store i64 0, i64* [[NUM_DEPS]], align 4, [[DBG33]]
; CHECK-NEXT:    [[TMP3:%.*]] = load i64, i64* [[NUM_DEPS]], align 4, [[DBG33]]
; CHECK-NEXT:    call void @nanos6_create_loop(%nanos6_task_info_t* @task_info_var_constants_loop0, %nanos6_task_invocation_info_t* @task_invocation_info_constants_loop0, i64 16, i8** [[TMP2]], i8** [[TMP1]], i64 8, i64 [[TMP3]], i64 0, i64 10, i64 0, i64 0), [[DBG33]]
; CHECK-NEXT:    [[TMP4:%.*]] = load %nanos6_task_args_constants_loop0*, %nanos6_task_args_constants_loop0** [[TMP0]], align 8, [[DBG33]]
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast %nanos6_task_args_constants_loop0* [[TMP4]] to i8*, [[DBG33]]
; CHECK-NEXT:    [[ARGS_END:%.*]] = getelementptr i8, i8* [[TMP5]], i64 16, [[DBG33]]
; CHECK-NEXT:    [[CAPT_GEP_:%.*]] = getelementptr [[NANOS6_TASK_ARGS_CONSTANTS_LOOP0:%.*]], %nanos6_task_args_constants_loop0* [[TMP4]], i32 0, i32 1, [[DBG33]]
; CHECK-NEXT:    store i32 0, i32* [[CAPT_GEP_]], align 4, [[DBG33]]
; CHECK-NEXT:    [[CAPT_GEP_4:%.*]] = getelementptr [[NANOS6_TASK_ARGS_CONSTANTS_LOOP0]], %nanos6_task_args_constants_loop0* [[TMP4]], i32 0, i32 2, [[DBG33]]
; CHECK-NEXT:    store i32 10, i32* [[CAPT_GEP_4]], align 4, [[DBG33]]
; CHECK-NEXT:    [[CAPT_GEP_5:%.*]] = getelementptr [[NANOS6_TASK_ARGS_CONSTANTS_LOOP0]], %nanos6_task_args_constants_loop0* [[TMP4]], i32 0, i32 3, [[DBG33]]
; CHECK-NEXT:    store i32 1, i32* [[CAPT_GEP_5]], align 4, [[DBG33]]
; CHECK-NEXT:    [[TMP6:%.*]] = load i8*, i8** [[TMP1]], align 8, [[DBG33]]
; CHECK-NEXT:    call void @nanos6_submit_task(i8* [[TMP6]]), [[DBG33]]
; CHECK-NEXT:    br label [[FINAL_END:%.*]], [[DBG33]]
; CHECK:       final.end:
; CHECK-NEXT:    ret void, [[DBG34:!dbg !.*]]
; CHECK:       final.then:
; CHECK-NEXT:    store i32 0, i32* [[I]], align 4, [[DBG33]]
; CHECK-NEXT:    br label [[FOR_COND:%.*]], [[DBG33]]
; CHECK:       for.cond:
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, i32* [[I]], align 4, [[DBG33]]
; CHECK-NEXT:    [[TMP8:%.*]] = icmp slt i32 [[TMP7]], 10, [[DBG33]]
; CHECK-NEXT:    br i1 [[TMP8]], label [[FOR_BODY:%.*]], label [[FINAL_END]], [[DBG33]]
; CHECK:       for.body:
; CHECK-NEXT:    br label [[FOR_INCR:%.*]], [[DBG34]]
; CHECK:       for.incr:
; CHECK-NEXT:    [[TMP9:%.*]] = load i32, i32* [[I]], align 4, [[DBG33]]
; CHECK-NEXT:    [[TMP10:%.*]] = add i32 [[TMP9]], 1, [[DBG33]]
; CHECK-NEXT:    store i32 [[TMP10]], i32* [[I]], align 4, [[DBG33]]
; CHECK-NEXT:    br label [[FOR_COND]], [[DBG33]]
; CHECK:       final.cond:
; CHECK-NEXT:    [[TMP11:%.*]] = call i32 @nanos6_in_final(), [[DBG33]]
; CHECK-NEXT:    [[TMP12:%.*]] = icmp ne i32 [[TMP11]], 0, [[DBG33]]
; CHECK-NEXT:    br i1 [[TMP12]], label [[FINAL_THEN:%.*]], label [[CODEREPL:%.*]], [[DBG33]]
;
entry:
  %i = alloca i32, align 4
  store i32 0, i32* %i, align 4, !dbg !33
  %0 = call token @llvm.directive.region.entry() [ "DIR.OSS"([9 x i8] c"TASK.FOR\00"), "QUAL.OSS.PRIVATE"(i32* %i), "QUAL.OSS.LOOP.IND.VAR"(i32* %i), "QUAL.OSS.LOOP.LOWER.BOUND"(i32 0), "QUAL.OSS.LOOP.UPPER.BOUND"(i32 10), "QUAL.OSS.LOOP.STEP"(i32 1), "QUAL.OSS.LOOP.TYPE"(i64 0, i64 1, i64 1, i64 1, i64 1), "QUAL.OSS.CAPTURED"(i32 0, i32 10, i32 1) ], !dbg !33
  call void @llvm.directive.region.exit(token %0), !dbg !33
  ret void, !dbg !34
}

attributes #0 = { noinline nounwind optnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-features"="+cx8,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind }

!llvm.dbg.cu = !{!0}
!llvm.module.flags = !{!3, !4}
!llvm.ident = !{!5}

!0 = distinct !DICompileUnit(language: DW_LANG_C99, file: !1, producer: "human", isOptimized: false, runtimeVersion: 0, emissionKind: NoDebug, enums: !2, nameTableKind: None)
!1 = !DIFile(filename: "<stdin>", directory: "")
!2 = !{}
!3 = !{i32 2, !"Debug Info Version", i32 3}
!4 = !{i32 1, !"wchar_size", i32 4}
!5 = !{!"clang version 11.0.0 "}
!6 = distinct !DISubprogram(name: "signed_loop_slt", scope: !7, file: !7, line: 1, type: !8, scopeLine: 1, flags: DIFlagPrototyped, spFlags: DISPFlagDefinition, unit: !0, retainedNodes: !2)
!7 = !DIFile(filename: "task_for_cond_and_register_check.ll", directory: "")
!8 = !DISubroutineType(types: !2)
!9 = !DILocation(line: 3, scope: !6)
!10 = !DILocation(line: 4, scope: !6)
!11 = distinct !DISubprogram(name: "signed_loop_sle", scope: !7, file: !7, line: 5, type: !8, scopeLine: 5, flags: DIFlagPrototyped, spFlags: DISPFlagDefinition, unit: !0, retainedNodes: !2)
!12 = !DILocation(line: 7, scope: !11)
!13 = !DILocation(line: 8, scope: !11)
!14 = distinct !DISubprogram(name: "signed_loop_sgt", scope: !7, file: !7, line: 9, type: !8, scopeLine: 9, flags: DIFlagPrototyped, spFlags: DISPFlagDefinition, unit: !0, retainedNodes: !2)
!15 = !DILocation(line: 11, scope: !14)
!16 = !DILocation(line: 12, scope: !14)
!17 = distinct !DISubprogram(name: "signed_loop_sge", scope: !7, file: !7, line: 13, type: !8, scopeLine: 13, flags: DIFlagPrototyped, spFlags: DISPFlagDefinition, unit: !0, retainedNodes: !2)
!18 = !DILocation(line: 15, scope: !17)
!19 = !DILocation(line: 16, scope: !17)
!20 = distinct !DISubprogram(name: "unsigned_loop_slt", scope: !7, file: !7, line: 18, type: !8, scopeLine: 18, flags: DIFlagPrototyped, spFlags: DISPFlagDefinition, unit: !0, retainedNodes: !2)
!21 = !DILocation(line: 20, scope: !20)
!22 = !DILocation(line: 21, scope: !20)
!23 = distinct !DISubprogram(name: "unsigned_loop_sle", scope: !7, file: !7, line: 22, type: !8, scopeLine: 22, flags: DIFlagPrototyped, spFlags: DISPFlagDefinition, unit: !0, retainedNodes: !2)
!24 = !DILocation(line: 24, scope: !23)
!25 = !DILocation(line: 25, scope: !23)
!26 = distinct !DISubprogram(name: "unsigned_loop_sgt", scope: !7, file: !7, line: 26, type: !8, scopeLine: 26, flags: DIFlagPrototyped, spFlags: DISPFlagDefinition, unit: !0, retainedNodes: !2)
!27 = !DILocation(line: 28, scope: !26)
!28 = !DILocation(line: 29, scope: !26)
!29 = distinct !DISubprogram(name: "unsigned_loop_sge", scope: !7, file: !7, line: 30, type: !8, scopeLine: 30, flags: DIFlagPrototyped, spFlags: DISPFlagDefinition, unit: !0, retainedNodes: !2)
!30 = !DILocation(line: 32, scope: !29)
!31 = !DILocation(line: 33, scope: !29)
!32 = distinct !DISubprogram(name: "constants_loop", scope: !7, file: !7, line: 35, type: !8, scopeLine: 35, spFlags: DISPFlagDefinition, unit: !0, retainedNodes: !2)
!33 = !DILocation(line: 37, scope: !32)
!34 = !DILocation(line: 38, scope: !32)
